{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8a0f72-5f81-4ce3-ab23-0fd1a6da8c78",
   "metadata": {},
   "source": [
    "# Logistic regression on the epsilon dataset\n",
    "\n",
    "This is a \"getting started\" exercise. Simple logistic regression on the [epsilon dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#epsilon), which contains 400,000 training data points with 2,000 features, and 100,000 test data points.\n",
    "\n",
    "This notebook is mostly to try things out. The \"real\" script is in ../logistic.py. To run this locally, I used a smaller version of the epsilon dataset, constructed by taking the first 1000 lines of the test set as the \"smaller training set\", and the last 200 lines of the test set as the \"smaller test set\", as follows (in bash, replace `~/jadeite/data/sources` with wherever your data directory is):\n",
    "\n",
    "``` bash\n",
    "mkdir -p ~/jadeite/data/sources/epsilon\n",
    "cd ~/jadeite/data/sources/epsilon\n",
    "wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/epsilon_normalized.t.bz2\n",
    "bunzip2 epsilon_normalized.t.bz2\n",
    "mv epsilon_normalized.t epsilon_normalized.t.full\n",
    "head epsilon_normalized.t.full -n 1000 > epsilon_normalized\n",
    "tail epsilon_normalized.t.full -n 200 > epsilon_normalized.t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6780e9-dca9-4542-a201-680a229eb919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-03 20:24:28.574937: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-03 20:24:28.574985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import data.epsilon as epsilon\n",
    "import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08d73ef-ef3d-474b-a086-2f3a746fadec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2001      \n",
      "=================================================================\n",
      "Total params: 2,001\n",
      "Trainable params: 2,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-03 20:24:29.690028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-03 20:24:29.690078: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-03 20:24:29.690099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zinfandel): /proc/driver/nvidia/version does not exist\n",
      "2021-07-03 20:24:29.690322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2000,)),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a87a69-e344-42ff-b4c6-e2ba4eb53ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-03 20:24:29.841419: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-03 20:24:29.841975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1992005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.6945 - accuracy: 0.4792\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.6943 - accuracy: 0.4917\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.6941 - accuracy: 0.4823\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.6940 - accuracy: 0.4802\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.6938 - accuracy: 0.4792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f624a9ded90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer='sgd', metrics=['accuracy'])\n",
    "nepochs = 5\n",
    "batch_size = 64\n",
    "dataset = epsilon.train_dataset().repeat(nepochs).batch(batch_size)\n",
    "model.fit(dataset, epochs=nepochs, steps_per_epoch = epsilon.ntrain // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22185e90-0057-47c0-bb06-fe2a7a788d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6930 - accuracy: 0.5150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6930496692657471, 'accuracy': 0.5149999856948853}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = epsilon.test_dataset().batch(batch_size)\n",
    "evaluation = model.evaluate(test_dataset, return_dict=True)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494054c9-9625-4888-8852-dc48d8cc54e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 of 5, 0 of 3, loss: 0.693686\r"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2000,)),\n",
    "])\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "nepochs = 5\n",
    "batch_size = 64\n",
    "nbatches = epsilon.ntest // batch_size\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    dataset = epsilon.test_dataset().batch(batch_size)\n",
    "    for i, (x, y) in dataset.enumerate():\n",
    "        with tf.GradientTape() as tape:\n",
    "            ŷ = model(x)\n",
    "            loss = loss_fn(y, ŷ)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "        if i % 10 == 0:\n",
    "            print(f\"epoch {epoch} of {nepochs}, {i} of {nbatches}, loss: {loss:f}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bfbace-5f2e-486d-b309-9eade56bb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 0...\n",
      "Accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "dataset = epsilon.test_dataset().batch(batch_size)\n",
    "nbatches = epsilon.ntest // batch_size\n",
    "accuracy_fn = tf.keras.metrics.BinaryAccuracy()\n",
    "for i, (x, y) in dataset.enumerate():\n",
    "    ŷ = model(x)\n",
    "    accuracy_fn.update_state(y, ŷ)\n",
    "    print(f\"{i} of {nbatches}...\", end='\\r')\n",
    "accuracy = accuracy_fn.result().numpy()\n",
    "print(f\"\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26f083-60b2-40e2-8ba7-952c936c6fa3",
   "metadata": {},
   "source": [
    "# Simple federated averaging\n",
    "\n",
    "Again, mostly an exercise, this is an attempt to use the tensorflow-federated framework with federated averaging to achieve the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5be377-9518-49e2-a627-13a05219aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbac75c-085b-4574-8180-40be030e9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4fe6e-286c-4e2b-bb89-50d991c35593",
   "metadata": {},
   "source": [
    "The `Dataset.shard()` method divides a dataset into several shards. Originally I had something like this:\n",
    "\n",
    "``` python\n",
    "def client_data_by_shard(client_id):\n",
    "    return train_dataset.shard(nclients, client_id)\n",
    "\n",
    "client_data = tff.simulation.datasets.ClientData.from_clients_and_fn(range(nclients), client_data_by_shard)\n",
    "```\n",
    "\n",
    "but we don't actually need a `ClientData` object, since TFF just takes in lists of `tf.data.Dataset` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff3e0de-989a-4cc7-a5f0-1cabef694bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclients = 10\n",
    "nrounds = 8\n",
    "batch_size = 64\n",
    "train_dataset = epsilon.train_dataset().batch(batch_size)\n",
    "client_shards = [train_dataset.shard(nclients, i) for i in range(nclients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44818506-6390-4d33-ab59-85877cb6936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 2000), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34780ac2-f4dc-478d-b698-615e250b2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2000,)),\n",
    "    ])\n",
    "\n",
    "def model_fn():\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=train_dataset.element_spec,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "\n",
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42738c5c-c5fc-440a-a735-5cb1b8900a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/czlee/jadeite/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/czlee/jadeite/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ServerState(model=ModelWeights(trainable=[array([[ 0.04946871],\n",
       "       [ 0.018157  ],\n",
       "       [ 0.03626599],\n",
       "       ...,\n",
       "       [ 0.0412962 ],\n",
       "       [-0.01557492],\n",
       "       [ 0.04785355]], dtype=float32), array([0.], dtype=float32)], non_trainable=[]), optimizer_state=[0], delta_aggregate_state=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), model_broadcast_state=())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = results.create_results_directory()\n",
    "log_dir = results_dir / 'logs'\n",
    "summary_writer = tf.summary.create_file_writer(str(log_dir))  # doesn't support Path objects\n",
    "\n",
    "state = iterative_process.initialize()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a04e1c0f-3934-459f-8609-48c8bac239a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0 of 8...\n",
      "round 1 of 8...\n",
      "round 2 of 8...\n",
      "round 3 of 8...\n",
      "round 4 of 8...\n",
      "round 5 of 8...\n",
      "round 6 of 8...\n",
      "round 7 of 8...\n"
     ]
    }
   ],
   "source": [
    "with summary_writer.as_default():\n",
    "    for r in range(nrounds):\n",
    "        print(f\"round {r} of {nrounds}...\")\n",
    "        state, metrics = iterative_process.next(state, client_shards)\n",
    "        for name, value in metrics['train'].items():\n",
    "            tf.summary.scalar(name, value, step=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d72379-c798-44f1-b624-4b0418531579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('binary_accuracy', 0.4873047), ('loss', 0.6933331)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca124d52-11f1-4723-884a-831ede821144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-33a86c49fa513b5e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-33a86c49fa513b5e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38443c4-b087-4327-8468-c7f3eb50bd60",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3a04db-ed9c-4885-8c70-7321d66d56c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 59ms/step - loss: 0.6929 - binary_accuracy: 0.5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6929421424865723, 0.5099999904632568]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = create_keras_model()\n",
    "test_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "state.model.assign_weights_to(test_model)\n",
    "test_dataset = epsilon.test_dataset().batch(batch_size)\n",
    "test_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32471191-6031-472c-a308-49ef7ee5067d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
